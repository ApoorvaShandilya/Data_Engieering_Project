{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a function \n",
    "\n",
    "def wiki_info(cities):\n",
    "    \n",
    "    list_for_df = []\n",
    "    \n",
    "    for city in cities:\n",
    "        \n",
    "        url = url = f'https://en.wikipedia.org/wiki/{city}'\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        \n",
    "        response_dict = {}\n",
    "        \n",
    "        \n",
    "        response_dict['city'] = soup.select('#firstHeading')[0].get_text()\n",
    "        response_dict['country'] = soup.select(\".infobox-data\")[0].get_text()\n",
    "        response_dict['latitude'] = soup.select(\".latitude\")[0].get_text()\n",
    "        response_dict['longitude'] = soup.select(\".longitude\")[0].get_text()\n",
    "        \n",
    "        if soup.select_one('.infobox-label:-soup-contains(\"Elevation\")'):\n",
    "            response_dict['elevation'] = soup.select_one('.infobox-label:-soup-contains(\"Elevation\")').find_next(class_='infobox-data').get_text()\n",
    "            response_dict['website'] = soup.select_one('.infobox-label:-soup-contains(\"Website\")').find_next(class_='infobox-data').get_text()\n",
    "        \n",
    "        if soup.select_one('th.infobox-header:-soup-contains(\"Population\")'):\n",
    "            response_dict['population'] = soup.select_one('th.infobox-header:-soup-contains(\"Population\")').parent.find_next_sibling().find(text=re.compile(r'\\d+'))\n",
    "\n",
    "        \n",
    "        list_for_df.append(response_dict)\n",
    "        \n",
    "    # creating the DataFrame\n",
    "    cities_info = pd.DataFrame(list_for_df)\n",
    "    \n",
    "    \n",
    "    return cities_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are trying with three city ,to include more citiy in the code we have to make cahnges in the above as per webscraping \n",
    "cities = ['Berlin', 'Hamburg', 'London']\n",
    "wiki_info(cities)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
